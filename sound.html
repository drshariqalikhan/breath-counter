<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>Breath Counter (Bluetooth Mic Priority)</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f0f0f0;
            color: #333;
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        .container {
            background-color: #fff;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            width: 100%;
            max-width: 400px;
            box-sizing: border-box;
        }
        h1 {
            text-align: center;
            color: #1a73e8;
            margin-top: 0;
        }
        button {
            display: block;
            width: 100%;
            padding: 12px;
            background-color: #1a73e8;
            color: white;
            border: none;
            border-radius: 5px;
            font-size: 16px;
            cursor: pointer;
            margin-bottom: 15px;
            transition: background-color 0.3s;
        }
        button:hover:not(:disabled) {
            background-color: #1558b3;
        }
        button:disabled {
            background-color: #ccc;
            cursor: not-allowed;
        }
        .stats {
            text-align: center;
            font-size: 18px;
            margin-bottom: 10px;
        }
        .stats span {
            font-weight: bold;
            font-size: 24px;
            color: #28a745;
        }
        #micInfo {
            text-align: center;
            font-size: 12px;
            color: #555;
            margin-bottom: 20px;
            min-height: 1em;
        }
        canvas {
            display: block;
            width: 100%;
            height: 150px;
            background-color: #e9e9e9;
            border-radius: 4px;
            margin-bottom: 20px;
        }
        .logs {
            margin-top: 20px;
            border: 1px solid #ddd;
            padding: 10px;
            height: 150px;
            overflow-y: auto;
            font-size: 12px;
            background-color: #f9f9f9;
            border-radius: 4px;
        }
        .logs p { margin: 2px 0; padding: 2px; border-bottom: 1px solid #eee; }
        .logs .error { color: red; }
        .logs .info { color: green; }
        .logs .warn { color: orange; }
        .logs .debug { color: blue; }
    </style>
</head>
<body>
    <div class="container">
        <h1>Breath Counter</h1>

        <button id="startButton">Start Monitoring</button>
        <button id="stopButton" disabled>Stop Monitoring</button>

        <div class="stats">
            Breaths: <span id="breathCount">0</span>
        </div>
        <div id="micInfo">Mic: (Inactive)</div>

        <canvas id="soundWaveCanvas"></canvas>
        <p style="text-align:center; font-size: 12px; margin-top: -15px; margin-bottom: 20px;">
            (Normalized energy in breath frequency range)
        </p>

        <h2>Logs</h2>
        <div id="logsContainer" class="logs">
            <p>App initialized. Waiting for user to start.</p>
        </div>
    </div>

    <script>
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const breathCountDisplay = document.getElementById('breathCount');
        const micInfoDisplay = document.getElementById('micInfo');
        const logsContainer = document.getElementById('logsContainer');
        const canvas = document.getElementById('soundWaveCanvas');
        const canvasCtx = canvas.getContext('2d');

        let audioContext;
        let analyser;
        let microphoneStream; // This will hold the final, potentially specific, stream
        let animationFrameId;

        let breathCount = 0;
        let isBreathing = false;
        let lastPeakTime = 0;
        const MIN_BREATH_INTERVAL = 1500; // milliseconds
        
        const FFT_SIZE = 2048;
        const LOW_FREQ_BREATH = 100; 
        const HIGH_FREQ_BREATH = 800;
        let BREATH_ENERGY_THRESHOLD = 50; 
        const MIN_PEAK_HEIGHT = 30; 
        const HYSTERESIS_FACTOR = 0.6;

        const MAX_LOGS = 50;
        const CHART_BUFFER_SIZE = 100;
        let chartData = [];

        function logMessage(message, type = 'info') {
            const p = document.createElement('p');
            const timestamp = new Date().toLocaleTimeString([], { hour: '2-digit', minute: '2-digit', second: '2-digit', fractionalSecondDigits: 3 });
            p.textContent = `[${timestamp}] ${message}`;
            p.className = type;
            logsContainer.appendChild(p);
            if (logsContainer.children.length > MAX_LOGS) {
                logsContainer.removeChild(logsContainer.firstChild);
            }
            logsContainer.scrollTop = logsContainer.scrollHeight;
        }

        async function startMonitoring() {
            logMessage('Attempting to start monitoring...');
            startButton.disabled = true; // Disable early

            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                logMessage('getUserMedia not supported on your browser!', 'error');
                alert('Your browser does not support microphone access.');
                startButton.disabled = false;
                return;
            }

            let initialStream;
            try {
                // 1. Request generic audio permission first to help unmask device labels
                initialStream = await navigator.mediaDevices.getUserMedia({ audio: true, video: false });
                logMessage('Initial generic microphone access granted.', 'info');
            } catch (err) {
                logMessage(`Error getting initial microphone permission: ${err.name} - ${err.message}`, 'error');
                alert(`Error accessing microphone: ${err.message}. Please ensure permission is granted.`);
                startButton.disabled = false;
                return;
            }

            let selectedDeviceId = null;
            let selectedDeviceLabel = "Default";

            try {
                const devices = await navigator.mediaDevices.enumerateDevices();
                const audioInputDevices = devices.filter(device => device.kind === 'audioinput');
                logMessage(`Found ${audioInputDevices.length} audio input devices:`, 'debug');
                audioInputDevices.forEach(d => logMessage(`  - Label: "${d.label}", ID: ${d.deviceId.substring(0,10)}...`, 'debug'));

                if (audioInputDevices.length > 0) {
                    // Heuristic: look for "bluetooth" or "headset" in label.
                    // Prefer devices that are NOT an "iPhone Microphone" if a BT one is found.
                    // iOS labels can be tricky; sometimes they are blank or generic.
                    let potentialBluetoothDevice = audioInputDevices.find(device => 
                        /bluetooth|headset/i.test(device.label) && !/iphone microphone/i.test(device.label)
                    );
                    
                    if (!potentialBluetoothDevice) { // Fallback if specific BT terms aren't found but multiple mics exist
                        potentialBluetoothDevice = audioInputDevices.find(device =>
                           device.label && // Ensure label exists
                           !/iphone microphone|built-in/i.test(device.label) && // Not clearly built-in
                           device.deviceId !== 'default' && // Not the abstract default device
                           audioInputDevices.length > 1 // Only if there's more than one mic
                        );
                    }

                    if (potentialBluetoothDevice) {
                        selectedDeviceId = potentialBluetoothDevice.deviceId;
                        selectedDeviceLabel = potentialBluetoothDevice.label || "Selected Non-Default";
                        logMessage(`Attempting to use specific device: ${selectedDeviceLabel} (ID: ${selectedDeviceId.substring(0,10)}...)`, 'info');
                    } else {
                        logMessage('No specific Bluetooth/external headset detected by label, or only one mic. Using system default.', 'warn');
                        // selectedDeviceId remains null, getUserMedia will pick default
                        if (audioInputDevices.length > 0 && initialStream.getAudioTracks()[0].label) {
                             selectedDeviceLabel = initialStream.getAudioTracks()[0].label || "Default";
                        }
                    }
                } else {
                    logMessage('No audio input devices found after initial grant. This is unexpected.', 'error');
                     // Stop the initial stream if it's still active for some reason
                    if (initialStream) initialStream.getTracks().forEach(track => track.stop());
                    startButton.disabled = false;
                    return;
                }

                // Stop the initial generic stream before requesting a specific one (if different)
                // or if we are just going to use the one we got.
                if (initialStream) {
                    initialStream.getTracks().forEach(track => track.stop());
                    logMessage('Stopped initial generic stream.', 'debug');
                }

                const constraints = {
                    audio: selectedDeviceId ? { deviceId: { exact: selectedDeviceId } } : true,
                    video: false
                };
                
                logMessage(`Requesting final microphone stream with constraints: ${JSON.stringify(constraints.audio)}`, 'debug');
                microphoneStream = await navigator.mediaDevices.getUserMedia(constraints);
                
                const currentTrack = microphoneStream.getAudioTracks()[0];
                const finalDeviceLabel = currentTrack.label || (selectedDeviceId ? selectedDeviceLabel : "System Default");
                micInfoDisplay.textContent = `Mic: ${finalDeviceLabel.substring(0,30)}${finalDeviceLabel.length > 30 ? '...' : ''}`;
                logMessage(`Successfully using microphone: "${finalDeviceLabel}"`, 'info');
                const settings = currentTrack.getSettings();
                if(settings.deviceId) logMessage(`Actual Device ID being used: ${settings.deviceId.substring(0,10)}...`, 'debug');


            } catch (err) {
                logMessage(`Error during device selection or final stream acquisition: ${err.name} - ${err.message}`, 'error');
                if (initialStream) initialStream.getTracks().forEach(track => track.stop());
                if (microphoneStream) microphoneStream.getTracks().forEach(track => track.stop());
                startButton.disabled = false;
                stopButton.disabled = true;
                micInfoDisplay.textContent = "Mic: Error";
                return;
            }
            
            // Proceed with AudioContext setup
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                logMessage(`AudioContext created. Sample rate: ${audioContext.sampleRate} Hz`, 'info');

                const source = audioContext.createMediaStreamSource(microphoneStream);
                
                analyser = audioContext.createAnalyser();
                analyser.fftSize = FFT_SIZE;
                analyser.smoothingTimeConstant = 0.8; 

                source.connect(analyser);
                
                const freqBinCount = analyser.frequencyBinCount;
                const nyquist = audioContext.sampleRate / 2;
                const lowBin = Math.max(0, Math.round(LOW_FREQ_BREATH / (nyquist / freqBinCount)));
                const highBin = Math.min(freqBinCount -1, Math.round(HIGH_FREQ_BREATH / (nyquist / freqBinCount)));
                logMessage(`Targeting frequencies: ${LOW_FREQ_BREATH}Hz - ${HIGH_FREQ_BREATH}Hz (Bins: ${lowBin}-${highBin})`, 'info');
                if (lowBin >= highBin) {
                    logMessage('Warning: Low frequency bin is not less than high frequency bin. Check FFT_SIZE and frequency settings.', 'warn');
                }


                stopButton.disabled = false;
                breathCount = 0;
                isBreathing = false;
                lastPeakTime = 0;
                chartData = [];
                updateBreathCountDisplay();

                processAudio(lowBin, highBin);

            } catch (err) {
                logMessage(`Error setting up AudioContext/Analyser: ${err.message}`, 'error');
                if (microphoneStream) microphoneStream.getTracks().forEach(track => track.stop());
                startButton.disabled = false;
                stopButton.disabled = true;
                micInfoDisplay.textContent = "Mic: Error";
            }
        }

        function stopMonitoring() {
            logMessage('Stopping monitoring...');
            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId);
                animationFrameId = null;
            }
            if (microphoneStream) {
                microphoneStream.getTracks().forEach(track => track.stop());
                logMessage('Microphone stream stopped.', 'info');
                microphoneStream = null;
            }
            if (audioContext && audioContext.state !== 'closed') {
                audioContext.close().then(() => logMessage('AudioContext closed.', 'info'));
                audioContext = null;
            }
            
            startButton.disabled = false;
            stopButton.disabled = true;
            isBreathing = false;
            chartData = []; 
            drawChart(); 
            micInfoDisplay.textContent = "Mic: (Inactive)";
        }

        function processAudio(lowBin, highBin) {
            if (!analyser) {
                logMessage('Analyser not ready in processAudio', 'error');
                stopMonitoring(); // Critical error, stop.
                return;
            }
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength); 

            analyser.getByteFrequencyData(dataArray);

            let sumEnergy = 0;
            let count = 0;
            for (let i = lowBin; i <= highBin; i++) {
                sumEnergy += dataArray[i];
                count++;
            }
            const avgEnergy = count > 0 ? sumEnergy / count : 0;
            
            chartData.push(avgEnergy);
            if (chartData.length > CHART_BUFFER_SIZE) {
                chartData.shift();
            }
            drawChart();

            const currentTime = Date.now();
            if (avgEnergy > MIN_PEAK_HEIGHT && avgEnergy > BREATH_ENERGY_THRESHOLD && !isBreathing) {
                isBreathing = true;
                // logMessage(`Potential inhale start (Energy: ${avgEnergy.toFixed(2)})`, 'debug');
            } else if (isBreathing && avgEnergy < BREATH_ENERGY_THRESHOLD * HYSTERESIS_FACTOR) {
                if (currentTime - lastPeakTime > MIN_BREATH_INTERVAL) {
                    breathCount++;
                    lastPeakTime = currentTime;
                    updateBreathCountDisplay();
                    logMessage(`Breath detected! Count: ${breathCount} (Energy fell to ${avgEnergy.toFixed(2)})`, 'info');
                } else {
                    // logMessage(`Breath-like sound too soon (Energy: ${avgEnergy.toFixed(2)})`, 'debug');
                }
                isBreathing = false;
            }
            
            animationFrameId = requestAnimationFrame(() => processAudio(lowBin, highBin));
        }
        
        function updateBreathCountDisplay() {
            breathCountDisplay.textContent = breathCount;
        }

        function drawChart() {
            canvasCtx.fillStyle = '#e9e9e9';
            canvasCtx.fillRect(0, 0, canvas.width, canvas.height);

            if (chartData.length === 0) return;

            canvasCtx.lineWidth = 2;
            canvasCtx.strokeStyle = '#1a73e8';
            canvasCtx.beginPath();

            const sliceWidth = canvas.width * 1.0 / chartData.length;
            let x = 0;

            for (let i = 0; i < chartData.length; i++) {
                const v = chartData[i] / 255.0; 
                const y = canvas.height - (v * canvas.height);

                if (i === 0) {
                    canvasCtx.moveTo(x, y);
                } else {
                    canvasCtx.lineTo(x, y);
                }
                x += sliceWidth;
            }
            canvasCtx.stroke();
        }
        
        function resizeCanvas() {
            const displayWidth  = canvas.clientWidth;
            const displayHeight = canvas.clientHeight;

            if (canvas.width  !== displayWidth || canvas.height !== displayHeight) {
                canvas.width  = displayWidth;
                canvas.height = displayHeight;
                drawChart();
            }
        }

        startButton.addEventListener('click', startMonitoring);
        stopButton.addEventListener('click', stopMonitoring);
        window.addEventListener('resize', resizeCanvas);

        resizeCanvas();
        logMessage('App ready. Connect Bluetooth headset if desired, then click "Start Monitoring".', 'info');
        // window.setBreathThreshold = (val) => { BREATH_ENERGY_THRESHOLD = val; logMessage(`Threshold set to ${val}`); };
        // console.log("You can use setBreathThreshold(value) in console to adjust sensitivity (uncomment in code).");

    </script>
</body>
</html>
